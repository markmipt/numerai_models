{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import rankdata\n",
    "import pickle\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataframe, unimportant=set()):\n",
    "    feature_columns = dataframe.columns\n",
    "    columns_to_remove = []\n",
    "    for feature in feature_columns:\n",
    "        if not feature.startswith('feature_'):\n",
    "            columns_to_remove.append(feature)\n",
    "    feature_columns = feature_columns.drop(columns_to_remove)\n",
    "    return sorted(feature_columns)\n",
    "\n",
    "def get_X_array(df, feature_columns):\n",
    "    return df.loc[:, feature_columns].values\n",
    "\n",
    "def get_Y_array(df):\n",
    "    return df.loc[:, 'target_kazutsugi'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_final = pickle.load(open('214_feature_columns_final_q01.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def _neutralize(df, columns, by, proportion=1.0):\n",
    "    scores = df[columns]\n",
    "    exposures = df[by].values\n",
    "    scores = scores - (proportion * exposures).dot(np.linalg.pinv(exposures).dot(scores))\n",
    "    return scores / scores.std()\n",
    "def _normalize(df):\n",
    "    X = (df.rank(method=\"first\") - 0.5) / len(df)\n",
    "    return scipy.stats.norm.ppf(X)\n",
    "def normalize_and_neutralize(df, columns, by, proportion=1.0):\n",
    "    # Convert the scores to a normal distribution\n",
    "    df[columns] = _normalize(df[columns])\n",
    "    df[columns] = _neutralize(df, columns, by, proportion)\n",
    "    return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOURNAMENT_NAME = \"kazutsugi\"\n",
    "TARGET_NAME = \"target_kazutsugi\"\n",
    "PREDICTION_NAME = \"prediction_kazutsugi\"\n",
    "\n",
    "BENCHMARK = 0\n",
    "BAND = 0.2\n",
    "\n",
    "\n",
    "# Submissions are scored by spearman correlation\n",
    "def score(df):\n",
    "    # method=\"first\" breaks ties based on order in array\n",
    "    return np.corrcoef(\n",
    "        df[TARGET_NAME],\n",
    "        df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n",
    "    )[0,1]\n",
    "\n",
    "\n",
    "# The payout function\n",
    "def payout(scores):\n",
    "    return ((scores - BENCHMARK)/BAND).clip(lower=-1, upper=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_folder = 'numerai_233'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "indatafile = open('%s/numerai_tournament_data.csv' % (cur_folder, ), 'r')\n",
    "p1file = open('%s/part1.csv' % (cur_folder, ), 'w')\n",
    "all_lines = indatafile.readlines()\n",
    "total_size = len(all_lines)\n",
    "first_half = int(1691469 / 2)\n",
    "for ln in all_lines[:first_half]:\n",
    "    p1file.write(ln)\n",
    "p1file.close()\n",
    "p2file = open('%s/part2.csv' % (cur_folder, ), 'w')\n",
    "p2file.write(all_lines[0])\n",
    "for ln in all_lines[first_half:]:\n",
    "    p2file.write(ln)\n",
    "p2file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(845733, 314)\n",
      "On validation the correlation has mean 0.040312616405054034 and std 0.02408954258205016\n",
      "On validation the average per-era payout is 0.20156308202527018\n",
      "On validation the correlation has mean 0.038254395585296475 and std 0.022160438957453385\n",
      "On validation the average per-era payout is 0.1912719779264824\n",
      "(812848, 314)\n",
      "On validation the correlation has mean 0.017075857728340953 and std 0.02906686178417882\n",
      "On validation the average per-era payout is 0.08537928864170478\n",
      "On validation the correlation has mean 0.02194948957558552 and std 0.02512039143759398\n",
      "On validation the average per-era payout is 0.10974744787792759\n"
     ]
    }
   ],
   "source": [
    "mdl_0 = pickle.load(open('210model_remove03.pickle', 'rb'))\n",
    "\n",
    "usef_columns = pickle.load(open('210features_remove03.pickle', 'rb'))\n",
    "neut_columns = pickle.load(open('210features_neut03.pickle', 'rb'))\n",
    "\n",
    "df2 = pd.read_csv('%s/part1.csv' % (cur_folder, ))\n",
    "print(df2.shape)\n",
    "\n",
    "df2[PREDICTION_NAME] = mdl_0.predict(get_X_array(df2, usef_columns))\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations3 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations3.mean()} and std {validation_correlations3.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations3).mean()}\")\n",
    "\n",
    "df2[\"preds_neutralized\"] = df2.groupby(\"era\").apply(\n",
    "    lambda x: normalize_and_neutralize(x, [PREDICTION_NAME], feature_columns_final, 1.0) # neutralize by 50% within each era\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "df2[\"preds_neutralized\"] = scaler.fit_transform(df2[[\"preds_neutralized\"]]) # transform back to 0-1\n",
    "\n",
    "df2[PREDICTION_NAME] = df2[\"preds_neutralized\"]\n",
    "\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations4 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations4.mean()} and std {validation_correlations4.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations4).mean()}\")\n",
    "\n",
    "ff_final = []\n",
    "ff_final.insert(0, 'id')\n",
    "ff_final.insert(0, 'era')\n",
    "ff_final.insert(0, 'data_type')\n",
    "ff_final.insert(0, 'target_kazutsugi')\n",
    "ff_final.insert(0, 'prediction_kazutsugi')\n",
    "\n",
    "df2 = df2[ff_final]\n",
    "\n",
    "\n",
    "df2 = df2.set_index(\"id\")\n",
    "df2[PREDICTION_NAME].to_csv('%s/kazutsugi' % (cur_folder, ) + '_submission_part1.csv', header='s')\n",
    "\n",
    "df2 = pd.read_csv('%s/part2.csv' % (cur_folder, ))\n",
    "print(df2.shape)\n",
    "\n",
    "df2[PREDICTION_NAME] = mdl_0.predict(get_X_array(df2, usef_columns))\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations3 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations3.mean()} and std {validation_correlations3.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations3).mean()}\")\n",
    "\n",
    "df2[\"preds_neutralized\"] = df2.groupby(\"era\").apply(\n",
    "    lambda x: normalize_and_neutralize(x, [PREDICTION_NAME], feature_columns_final, 1.0) # neutralize by 50% within each era\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "df2[\"preds_neutralized\"] = scaler.fit_transform(df2[[\"preds_neutralized\"]]) # transform back to 0-1\n",
    "\n",
    "df2[PREDICTION_NAME] = df2[\"preds_neutralized\"]\n",
    "\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations4 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations4.mean()} and std {validation_correlations4.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations4).mean()}\")\n",
    "\n",
    "ff_final = []\n",
    "ff_final.insert(0, 'id')\n",
    "ff_final.insert(0, 'era')\n",
    "ff_final.insert(0, 'data_type')\n",
    "ff_final.insert(0, 'target_kazutsugi')\n",
    "ff_final.insert(0, 'prediction_kazutsugi')\n",
    "\n",
    "df2 = df2[ff_final]\n",
    "\n",
    "\n",
    "df2 = df2.set_index(\"id\")\n",
    "df2[PREDICTION_NAME].to_csv('%s/kazutsugi' % (cur_folder, ) + '_submission_part2.csv', header='s')\n",
    "\n",
    "p1file = open('%s/kazutsugi_submission_part1.csv' % (cur_folder, ), 'r')\n",
    "p2file = open('%s/kazutsugi_submission_part2.csv' % (cur_folder, ), 'r')\n",
    "poutfile = open('%s/kazutsugi_submission.csv' % (cur_folder, ), 'w')\n",
    "for ln in p1file.readlines():\n",
    "    poutfile.write(ln)\n",
    "for ln in p2file.readlines()[1:]:\n",
    "    poutfile.write(ln)\n",
    "poutfile.close()\n",
    "\n",
    "df1 = pd.read_csv('%s/kazutsugi_submission.csv' % (cur_folder, ))\n",
    "\n",
    "df1['prediction_kazutsugi'] = df1['prediction_kazutsugi'] - df1['prediction_kazutsugi'].min()\n",
    "df1['prediction_kazutsugi'] = df1['prediction_kazutsugi'] / df1['prediction_kazutsugi'].max()\n",
    "\n",
    "df1 = df1.set_index(\"id\")\n",
    "df1['prediction_kazutsugi'].to_csv('%s/kazutsugi' % (cur_folder, ) + '_jackerparker6.csv', header='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 119, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(usef_columns), len(neut_columns), len(feature_columns_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(usef_columns).intersection(set(neut_columns))), len(set(usef_columns).intersection(set(neut_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_0 = pickle.load(open('210model_remove03.pickle', 'rb'))\n",
    "\n",
    "usef_columns = pickle.load(open('210features_remove03.pickle', 'rb'))\n",
    "neut_columns = pickle.load(open('210features_neut03.pickle', 'rb'))\n",
    "\n",
    "df2 = pd.read_csv('%s/part1.csv' % (cur_folder, ))\n",
    "print(df2.shape)\n",
    "\n",
    "df2[PREDICTION_NAME] = mdl_0.predict(get_X_array(df2, usef_columns))\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations3 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations3.mean()} and std {validation_correlations3.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations3).mean()}\")\n",
    "\n",
    "# df2[\"preds_neutralized\"] = df2.groupby(\"era\").apply(\n",
    "#     lambda x: normalize_and_neutralize(x, [PREDICTION_NAME], feature_columns_final, 1.0) # neutralize by 50% within each era\n",
    "# )\n",
    "# scaler = MinMaxScaler()\n",
    "# df2[\"preds_neutralized\"] = scaler.fit_transform(df2[[\"preds_neutralized\"]]) # transform back to 0-1\n",
    "\n",
    "# df2[PREDICTION_NAME] = df2[\"preds_neutralized\"]\n",
    "\n",
    "# validation_data = df2[df2.data_type == \"validation\"]\n",
    "# validation_correlations4 = validation_data.groupby(\"era\").apply(score)\n",
    "# print(f\"On validation the correlation has mean {validation_correlations4.mean()} and std {validation_correlations4.std()}\")\n",
    "# print(f\"On validation the average per-era payout is {payout(validation_correlations4).mean()}\")\n",
    "\n",
    "ff_final = []\n",
    "ff_final.insert(0, 'id')\n",
    "ff_final.insert(0, 'era')\n",
    "ff_final.insert(0, 'data_type')\n",
    "ff_final.insert(0, 'target_kazutsugi')\n",
    "ff_final.insert(0, 'prediction_kazutsugi')\n",
    "\n",
    "df2 = df2[ff_final]\n",
    "\n",
    "\n",
    "df2 = df2.set_index(\"id\")\n",
    "df2[PREDICTION_NAME].to_csv('%s/kazutsugi' % (cur_folder, ) + '_submission_part1.csv', header='s')\n",
    "\n",
    "df2 = pd.read_csv('%s/part2.csv' % (cur_folder, ))\n",
    "print(df2.shape)\n",
    "\n",
    "df2[PREDICTION_NAME] = mdl_0.predict(get_X_array(df2, usef_columns))\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations3 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations3.mean()} and std {validation_correlations3.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations3).mean()}\")\n",
    "\n",
    "# df2[\"preds_neutralized\"] = df2.groupby(\"era\").apply(\n",
    "#     lambda x: normalize_and_neutralize(x, [PREDICTION_NAME], feature_columns_final, 1.0) # neutralize by 50% within each era\n",
    "# )\n",
    "# scaler = MinMaxScaler()\n",
    "# df2[\"preds_neutralized\"] = scaler.fit_transform(df2[[\"preds_neutralized\"]]) # transform back to 0-1\n",
    "\n",
    "# df2[PREDICTION_NAME] = df2[\"preds_neutralized\"]\n",
    "\n",
    "# validation_data = df2[df2.data_type == \"validation\"]\n",
    "# validation_correlations4 = validation_data.groupby(\"era\").apply(score)\n",
    "# print(f\"On validation the correlation has mean {validation_correlations4.mean()} and std {validation_correlations4.std()}\")\n",
    "# print(f\"On validation the average per-era payout is {payout(validation_correlations4).mean()}\")\n",
    "\n",
    "ff_final = []\n",
    "ff_final.insert(0, 'id')\n",
    "ff_final.insert(0, 'era')\n",
    "ff_final.insert(0, 'data_type')\n",
    "ff_final.insert(0, 'target_kazutsugi')\n",
    "ff_final.insert(0, 'prediction_kazutsugi')\n",
    "\n",
    "df2 = df2[ff_final]\n",
    "\n",
    "\n",
    "df2 = df2.set_index(\"id\")\n",
    "df2[PREDICTION_NAME].to_csv('%s/kazutsugi' % (cur_folder, ) + '_submission_part2.csv', header='s')\n",
    "\n",
    "p1file = open('%s/kazutsugi_submission_part1.csv' % (cur_folder, ), 'r')\n",
    "p2file = open('%s/kazutsugi_submission_part2.csv' % (cur_folder, ), 'r')\n",
    "poutfile = open('%s/kazutsugi_submission.csv' % (cur_folder, ), 'w')\n",
    "for ln in p1file.readlines():\n",
    "    poutfile.write(ln)\n",
    "for ln in p2file.readlines()[1:]:\n",
    "    poutfile.write(ln)\n",
    "poutfile.close()\n",
    "\n",
    "df1 = pd.read_csv('%s/kazutsugi_submission.csv' % (cur_folder, ))\n",
    "\n",
    "df1['prediction_kazutsugi'] = df1['prediction_kazutsugi'] - df1['prediction_kazutsugi'].min()\n",
    "df1['prediction_kazutsugi'] = df1['prediction_kazutsugi'] / df1['prediction_kazutsugi'].max()\n",
    "\n",
    "df1 = df1.set_index(\"id\")\n",
    "df1['prediction_kazutsugi'].to_csv('%s/kazutsugi' % (cur_folder, ) + '_jackerparker3.csv', header='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(845733, 314)\n",
      "On validation the correlation has mean 0.040312616405054034 and std 0.02408954258205016\n",
      "On validation the average per-era payout is 0.20156308202527018\n",
      "On validation the correlation has mean 0.029215425636591134 and std 0.01804659818969637\n",
      "On validation the average per-era payout is 0.14607712818295565\n",
      "(812848, 314)\n",
      "On validation the correlation has mean 0.017075857728340953 and std 0.02906686178417882\n",
      "On validation the average per-era payout is 0.08537928864170478\n",
      "On validation the correlation has mean 0.02617351996274575 and std 0.014085384958865058\n",
      "On validation the average per-era payout is 0.13086759981372875\n"
     ]
    }
   ],
   "source": [
    "mdl_0 = pickle.load(open('210model_remove03.pickle', 'rb'))\n",
    "\n",
    "usef_columns = pickle.load(open('210features_remove03.pickle', 'rb'))\n",
    "neut_columns = pickle.load(open('210features_neut03.pickle', 'rb'))\n",
    "\n",
    "df2 = pd.read_csv('%s/part1.csv' % (cur_folder, ))\n",
    "print(df2.shape)\n",
    "\n",
    "df2[PREDICTION_NAME] = mdl_0.predict(get_X_array(df2, usef_columns))\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations3 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations3.mean()} and std {validation_correlations3.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations3).mean()}\")\n",
    "\n",
    "df2[\"preds_neutralized\"] = df2.groupby(\"era\").apply(\n",
    "    lambda x: normalize_and_neutralize(x, [PREDICTION_NAME], neut_columns, 1.0) # neutralize by 50% within each era\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "df2[\"preds_neutralized\"] = scaler.fit_transform(df2[[\"preds_neutralized\"]]) # transform back to 0-1\n",
    "\n",
    "df2[PREDICTION_NAME] = df2[\"preds_neutralized\"]\n",
    "\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations4 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations4.mean()} and std {validation_correlations4.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations4).mean()}\")\n",
    "\n",
    "ff_final = []\n",
    "ff_final.insert(0, 'id')\n",
    "ff_final.insert(0, 'era')\n",
    "ff_final.insert(0, 'data_type')\n",
    "ff_final.insert(0, 'target_kazutsugi')\n",
    "ff_final.insert(0, 'prediction_kazutsugi')\n",
    "\n",
    "df2 = df2[ff_final]\n",
    "\n",
    "\n",
    "df2 = df2.set_index(\"id\")\n",
    "df2[PREDICTION_NAME].to_csv('%s/kazutsugi' % (cur_folder, ) + '_submission_part1.csv', header='s')\n",
    "\n",
    "df2 = pd.read_csv('%s/part2.csv' % (cur_folder, ))\n",
    "print(df2.shape)\n",
    "\n",
    "df2[PREDICTION_NAME] = mdl_0.predict(get_X_array(df2, usef_columns))\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations3 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations3.mean()} and std {validation_correlations3.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations3).mean()}\")\n",
    "\n",
    "df2[\"preds_neutralized\"] = df2.groupby(\"era\").apply(\n",
    "    lambda x: normalize_and_neutralize(x, [PREDICTION_NAME], neut_columns, 1.0) # neutralize by 50% within each era\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "df2[\"preds_neutralized\"] = scaler.fit_transform(df2[[\"preds_neutralized\"]]) # transform back to 0-1\n",
    "\n",
    "df2[PREDICTION_NAME] = df2[\"preds_neutralized\"]\n",
    "\n",
    "validation_data = df2[df2.data_type == \"validation\"]\n",
    "validation_correlations4 = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations4.mean()} and std {validation_correlations4.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations4).mean()}\")\n",
    "\n",
    "ff_final = []\n",
    "ff_final.insert(0, 'id')\n",
    "ff_final.insert(0, 'era')\n",
    "ff_final.insert(0, 'data_type')\n",
    "ff_final.insert(0, 'target_kazutsugi')\n",
    "ff_final.insert(0, 'prediction_kazutsugi')\n",
    "\n",
    "df2 = df2[ff_final]\n",
    "\n",
    "\n",
    "df2 = df2.set_index(\"id\")\n",
    "df2[PREDICTION_NAME].to_csv('%s/kazutsugi' % (cur_folder, ) + '_submission_part2.csv', header='s')\n",
    "\n",
    "p1file = open('%s/kazutsugi_submission_part1.csv' % (cur_folder, ), 'r')\n",
    "p2file = open('%s/kazutsugi_submission_part2.csv' % (cur_folder, ), 'r')\n",
    "poutfile = open('%s/kazutsugi_submission.csv' % (cur_folder, ), 'w')\n",
    "for ln in p1file.readlines():\n",
    "    poutfile.write(ln)\n",
    "for ln in p2file.readlines()[1:]:\n",
    "    poutfile.write(ln)\n",
    "poutfile.close()\n",
    "\n",
    "df1 = pd.read_csv('%s/kazutsugi_submission.csv' % (cur_folder, ))\n",
    "\n",
    "df1['prediction_kazutsugi'] = df1['prediction_kazutsugi'] - df1['prediction_kazutsugi'].min()\n",
    "df1['prediction_kazutsugi'] = df1['prediction_kazutsugi'] / df1['prediction_kazutsugi'].max()\n",
    "\n",
    "df1 = df1.set_index(\"id\")\n",
    "df1['prediction_kazutsugi'].to_csv('%s/kazutsugi' % (cur_folder, ) + '_jackerparker2.csv', header='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('%s/kazutsugi' % (cur_folder, ) + '_jackerparker2.csv')\n",
    "df6 = pd.read_csv('%s/kazutsugi' % (cur_folder, ) + '_jackerparker6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df2.copy()\n",
    "df10['prediction_kazutsugi'] = rankdata(df2['prediction_kazutsugi']) + rankdata(df6['prediction_kazutsugi'])\n",
    "df10 = df10.set_index(\"id\")\n",
    "df10['prediction_kazutsugi'] = df10['prediction_kazutsugi'] - df10['prediction_kazutsugi'].min()\n",
    "df10['prediction_kazutsugi'] = df10['prediction_kazutsugi'] / df10['prediction_kazutsugi'].max()\n",
    "df10.to_csv('%s/kazutsugi' % (cur_folder, ) + '_jackerparker10.csv', header='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
